{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def normalize(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_f1(prediction, ground_truth):\n",
    "    if prediction is None:\n",
    "        return 0.0\n",
    "    prediction_tokens = normalize(prediction).split()\n",
    "    ground_truth_tokens = normalize(ground_truth).split()\n",
    "\n",
    "    common = set(prediction_tokens) & set(ground_truth_tokens)\n",
    "    num_same = len(common)\n",
    "\n",
    "    if num_same == 0:\n",
    "        return 0.0\n",
    "\n",
    "    precision = num_same / len(prediction_tokens)\n",
    "    recall = num_same / len(ground_truth_tokens)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    if prediction is None:\n",
    "        return 0.0\n",
    "    return int(normalize(prediction) == normalize(ground_truth))\n",
    "\n",
    "def evaluate(predictions):\n",
    "    total = len(predictions)\n",
    "    f1_total = []\n",
    "    em_total = []\n",
    "\n",
    "    for item in predictions:\n",
    "        # if item['pred_answer_ori'] == None:\n",
    "        pred = item['pred_answer']\n",
    "        # else:\n",
    "        #     pred = item['pred_answer_ori']\n",
    "        gts = item['gt']\n",
    "\n",
    "        # 若gt是str，统一转换为列表处理\n",
    "        if isinstance(gts, str):\n",
    "            gts = [gts]\n",
    "\n",
    "        f1 = max([compute_f1(pred, gt) for gt in gts])\n",
    "        em = max([exact_match_score(pred, gt) for gt in gts])\n",
    "        if em == 1:\n",
    "            f1 = 1\n",
    "\n",
    "        f1_total.append(f1)\n",
    "        em_total.append(em)\n",
    "\n",
    "    return {\n",
    "        \"avg_f1\": sum(f1_total) / total if total > 0 else 0,\n",
    "        \"avg_em\": sum(em_total) / total if total > 0 else 0,\n",
    "        \"simple_f1\": sum(f1_total[:75]) / 75 if total > 0 else 0,\n",
    "        \"simple_em\": sum(em_total[:75]) / 75 if total > 0 else 0,\n",
    "        \"hard_f1\": sum(f1_total[75:]) / 75 if total > 0 else 0,\n",
    "        \"hard_em\": sum(em_total[75:]) / 75 if total > 0 else 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12576 125 7405 2417\n",
    "\n",
    "import json\n",
    "with open('7B_df.json', 'r') as f:\n",
    "    combine_results = json.load(f)\n",
    "print(len(combine_results))\n",
    "\n",
    "count_none = 0\n",
    "for item in combine_results:\n",
    "    if item['pred_answer'] == None:\n",
    "        count_none += 1\n",
    "print(count_none)\n",
    "results = evaluate(combine_results)\n",
    "print(*[f\"{results[k]*100:.2f}\" for k in ['simple_f1', 'simple_em', 'hard_f1', 'hard_em', 'avg_f1', 'avg_em']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r1-v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
